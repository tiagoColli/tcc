<p>In this section we will have a hands-on using the feature store. So that this tutorial can be followed without any major problems, please make sure that you have all the dependencies installed:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[Spark 3.0.2
Hadoop 2.7
PySpark 3.0.1
PyArrow 2.0.0]]></ac:plain-text-body>
</ac:structured-macro>
<p>When you install the packages, the python dependencies that can be installed via pip will be downloaded and installed.</p>
<h2>Creation of the .env file</h2>
<p>Another important factor for the correct functioning of the feature store and to facilitate your work is the <em>.env</em> file.</p>
<p>Write the following parameters and settings in a file called <em>.env</em> and place your AWS credentials on them. Also make sure that the credentials provided have access to that bucket in which the features are stored.</p>
<p>The parameters shown below are the default parameters for operation.</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[AWS_ACCESS_KEY_ID="myawskey"
AWS_SECRET_ACCESS_KEY="myawssecret"]]></ac:plain-text-body>
</ac:structured-macro>
<h2>Packages and Import</h2>
<p>To import the Reader module, simply:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[from willfs import Reader]]></ac:plain-text-body>
</ac:structured-macro>
<p>The Writer module is only available to use in Amazon EMR. This package is not present in this distributed library. Please contact the Data Team in Slack to require the access to the WILLFS-EMR package.</p>
<h2>Using the CLI to interact with the feature store</h2>
<p>When installing the willfs package, a built in cli will be avaible, there are several functions you can use to interact with the feature store. First, we can list all features from the feature store using the cli:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">bash</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[willfs list-features]]></ac:plain-text-body>
</ac:structured-macro>
<p>The response from the command line will be like:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[    Feature                   GroupingKey          Size          Last Modified
0    | feature_1               | index             581          2021-02-23 16:55:47
1    | feature_2               | index             1443         2021-02-12 12:36:22
2    | feature_3               | index             1448         2021-02-12 12:32:18
3    | application_yearmonth   | id_card_account   1885         2021-02-17 11:06:03
4    | area_id                 | dr_number         312          2021-02-23 16:38:51
5    | area_name               | dr_number         316          2021-02-23 16:38:10
6    | cnt_bvs_queries_ever    | id_card_account   1222         2021-02-12 13:45:50
7    | cnt_serasa_queries_ever | id_card_account   1231         2021-02-12 13:50:10
8    | date_diff               | id_card_accoun    1192         2021-02-12 14:14:44
9    | days_since_application  | id_card_account   1231         2021-02-12 14:10:36
10   | decil_score_shortterm   | id_card_account   1226         2021-02-12 13:37:26]]></ac:plain-text-body>
</ac:structured-macro>
<p>You can also use the command bellow to check the versions of a given feature:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">bash</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[willfs list-feature-version `featurename`]]></ac:plain-text-body>
</ac:structured-macro>
<h2>Reading Features</h2>
<p>To read the features directly from the feature store.</p>
<p>The first step is to create an instance of the Reader.</p>
<p>If you want the returned dataset to be a <strong>Pandas</strong> dataset, simply:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[will_reader = Reader()]]></ac:plain-text-body>
</ac:structured-macro>
<p>Otherwise, if you want the returned dataset to be a <strong>Spark</strong> dataset, simply:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[will_reader = Reader(spark=True)]]></ac:plain-text-body>
</ac:structured-macro>
<ac:structured-macro ac:name="info">
<ac:rich-text-body>
<p>Remember to always use the instance will_reader.spark instance of Spark. </p>
</ac:rich-text-body>
</ac:structured-macro>
<p>If you start another instance in you execution code, some conflicts may arise.</p>
<p>If you want to use our staging bucket, you can set the bucket simply:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[will_reader = Reader(environment='pag')]]></ac:plain-text-body>
</ac:structured-macro>
<p>To read a given feature, simply</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[read_df = will_reader.read_feature('feature_1')]]></ac:plain-text-body>
</ac:structured-macro>
<p>If you want to read multiple features, simply:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[read_df = will_reader.read_multiple_features(['feature_1','feature_2','feature_3'])]]></ac:plain-text-body>
</ac:structured-macro>
<ac:structured-macro ac:name="info">
<ac:rich-text-body>
<p>Always verify the grouping key columns when reading multiple features,</p>
</ac:rich-text-body>
</ac:structured-macro>
<p>they must be the same.</p>
<p>If you want more informations for a single feature, you can read the metadata:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">python</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[metadata = will_reader.read_metadata('feature_1')]]></ac:plain-text-body>
</ac:structured-macro>
<h2>Conclusion</h2>
<p>In this tutorial, you learned how to write and read features in the features store, for both Spark and Pandas dataframe.</p>
<p>Also, you can read metadata and list the features. You may find in the next pages a detailed description of each available function.</p>
<p><em>If you have any doubts, please donâ€™t hesitate to contact us in our slack data channel.</em></p>
